{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY = <YOUR_ACCESS_KEY>\n",
    "# Encode the Secret Key to remove any \"/\" characters\n",
    "SECRET_KEY = <YOUR_SECRET_KEY>\n",
    "AWS_BUCKET_SOURCE = \"tweetdump1\"\n",
    "AWS_BUCKET_TARGET = \"tableaudump1\"\n",
    "MOUNT_NAME = \"/mnt/mount\"\n",
    "DUMP_NAME = \"/mnt/dump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#   dbutils.fs.unmount(MOUNT_NAME) # Use this to unmount as needed\n",
    "# except:\n",
    "#   print(\"{} already unmounted\".format(MOUNT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  dbutils.fs.mount(\"s3a://{}:{}@{}\".format(ACCESS_KEY, SECRET_KEY, AWS_BUCKET_SOURCE), MOUNT_NAME)\n",
    "except:\n",
    "  print(\"Mount {} already mounted. Run previous cells to unmount first\".format(MOUNT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  dbutils.fs.mount(\"s3a://{}:{}@{}\".format(ACCESS_KEY, SECRET_KEY, AWS_BUCKET_TARGET), DUMP_NAME)\n",
    "except:\n",
    "  print(\"Dump {} already mounted. Run previous cells to unmount first\".format(DUMP_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%fs ls /mnt/mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%fs ls /mnt/dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%fs head /mnt/mount/tweets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/mnt/mount/tweets.json'\n",
    "df = (spark.\n",
    "      read.\n",
    "      json(path)\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfCount = df.count()\n",
    "dfCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, LongType, StringType\n",
    "\n",
    "tweetSchema = StructType([\n",
    "  StructField(\"id\", LongType(), True),\n",
    "  StructField(\"user\", StructType([\n",
    "    StructField(\"id\", LongType(), True)\n",
    "  ]), True),  \n",
    "  StructField(\"lang\", StringType(), True),\n",
    "  StructField(\"text\", StringType(), True),\n",
    "  StructField(\"created_at\", StringType(), True)\n",
    "])\n",
    "\n",
    "tweetDF = spark.read.schema(tweetSchema).json(path)\n",
    "\n",
    "display(tweetDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "tweetFilteredDF = (tweetDF\n",
    "  .filter(col(\"id\").isNotNull())\n",
    ")\n",
    "\n",
    "display(tweetFilteredDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "timestampFormat = \"EEE MMM dd HH:mm:ss ZZZZZ yyyy\"\n",
    "tweetFinalDF = tweetFilteredDF.select(col(\"id\").alias(\"tweetID\"), \n",
    "  col(\"user.id\").alias(\"userID\"), \n",
    "  col(\"lang\").alias(\"language\"),\n",
    "  col(\"text\"),\n",
    "  unix_timestamp(\"created_at\", timestampFormat).cast(TimestampType()).alias(\"createdAt\")\n",
    ")\n",
    "\n",
    "display(tweetFinalDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetPND = tweetFinalDF.toPandas()\n",
    "tweetPND[\"Sentiment\"]=tweetPND[\"text\"].apply(lambda x:tb(x).sentiment.polarity)\n",
    "tweetSentimentDF = spark.createDataFrame(tweetPND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetSentimentDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetSentimentDF.write.mode(\"overwrite\").parquet(\"/mnt/dump/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "Transform_Load",
  "notebookId": 1257711982441151
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
